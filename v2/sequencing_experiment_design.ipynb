{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequencing Experiment Design\n",
    "Comparing capping and no capping for a coupling rate of 0.99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Parv\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\Bio\\Application\\__init__.py:39: BiopythonDeprecationWarning: The Bio.Application modules and modules relying on it have been deprecated.\n",
      "\n",
      "Due to the on going maintenance burden of keeping command line application\n",
      "wrappers up to date, we have decided to deprecate and eventually remove these\n",
      "modules.\n",
      "\n",
      "We instead now recommend building your command line and invoking it directly\n",
      "with the subprocess module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from seq_stat import align\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from aligned_clustering import conduct_align_clustering\n",
    "from utils import get_original_strands, read_synthesized_strands_from_file\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading original strands and synthesized strands\n",
    "\n",
    "original_strands_filepath = r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\data\\multiple_cr_post_seq_reads_badread\\original_strands.txt\"\n",
    "synthesized_strands_filepath = r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\data\\multiple_cr_post_seq_reads_badread\\synthesized.fasta\"\n",
    "\n",
    "# Read original strands from the file\n",
    "original_strand_ids, coupling_rates, capping_flags, original_strands = get_original_strands(original_strand_filepath=original_strands_filepath)\n",
    "\n",
    "# Read synthesised strands from file - 360,000 of these\n",
    "synthesized_strands, synthesized_strand_ids = read_synthesized_strands_from_file(synthesized_strands_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating padded file for Badread\n",
    "\n",
    "def generate_random_bases(n_bases):\n",
    "\n",
    "    bases = ['A', 'C', 'T', 'G']\n",
    "    return \"\".join([random.choice(bases) for i in range(n_bases)])\n",
    "    \n",
    "\n",
    "def create_badread_data(synthesized_strands, synthesized_strand_ids, write_filename='padded_synth.fasta'):\n",
    "\n",
    "    random.shuffle(synthesized_strands)\n",
    "    synthesized_padded_dict = {}\n",
    "    with open(write_filename, 'w') as f:\n",
    "        for strand, base_id in zip(synthesized_strands, synthesized_strand_ids):\n",
    "            \n",
    "            #strand = generate_random_bases(200) + strand\n",
    "            unique_id = str(uuid.uuid4())\n",
    "            f.write(f\">{unique_id}\\n\")\n",
    "            f.write(strand + '\\n\\n')\n",
    "            synthesized_padded_dict[unique_id] = strand\n",
    "\n",
    "    return synthesized_padded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesized_strands_sampled = random.sample(synthesized_strands, 1000)\n",
    "synthesized_padded_dict = create_badread_data(synthesized_strands=synthesized_strands, synthesized_strand_ids=synthesized_strand_ids, write_filename='synth_unpadded.fasta')\n",
    "\n",
    "# Need to be saving this dict - fuck me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Post Badread data processing\n",
    "\n",
    "def parse_biopython(input_fastq):\n",
    "    for record in SeqIO.parse(input_fastq, 'fastq'):\n",
    "        yield record\n",
    "        \n",
    "def postprocess_sequencing_data(fastq_filepath, original_strand_ids, original_strands, synthesized_padded_dict=None, reverse_oriented=False, filter=False):\n",
    "    \"\"\"\n",
    "    The record description contains the strand starting, ending and orientation\n",
    "    \"\"\"\n",
    "    sequenced_strands = []\n",
    "    for i, record in tqdm(enumerate(parse_biopython(fastq_filepath))):\n",
    "\n",
    "        strand_id = record.description.split()[1].split(',')[0]\n",
    "        strand = str(record.seq)\n",
    "\n",
    "        if reverse_oriented:\n",
    "            ## Correcting orientation if it is wrong\n",
    "            try:\n",
    "                orientation = record.description.split()[1].split(',')[2]\n",
    "                if orientation == '-strand':\n",
    "                    strand = strand[::-1]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # Aligning to the target strand if we are filtering        \n",
    "        if filter:\n",
    "            if strand_id in synthesized_padded_dict.keys():\n",
    "                    target_strand = synthesized_padded_dict[strand_id]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            aligned, identity, indices = align(target_strand, strand)\n",
    "\n",
    "            if identity > 0.7:\n",
    "                sequenced_strands.append(strand)\n",
    "        else:\n",
    "            sequenced_strands.append(strand)\n",
    "\n",
    "    return sequenced_strands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fd8de947d24bbaa266376a8ff5a5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequenced strands = 152831\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fastq_filepath = r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\data\\multiple_cr_post_seq_reads_badread\\reads.fastq\"\n",
    "sequenced_strands = postprocess_sequencing_data(fastq_filepath=fastq_filepath, original_strand_ids=original_strand_ids, original_strands=original_strands, filter=False, reverse_oriented=True)\n",
    "print(f\"Number of sequenced strands = {len(sequenced_strands)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clustering \n",
    "\n",
    "def cluster_data(original_strands, sequenced_strands):\n",
    "    recoveries = conduct_align_clustering(\n",
    "            original_strand=original_strands,\n",
    "            trimmed_seqs=sequenced_strands,\n",
    "            multiple=True\n",
    "        )\n",
    "    return list(recoveries['recoveries'].values())\n",
    "\n",
    "# Post Clustering Analysis\n",
    "\n",
    "def post_process_results(recoveries_strands, capping_flags, coupling_rates):\n",
    "\n",
    "    columns = [\n",
    "    'capping',\n",
    "    'coupling_rate',\n",
    "    'pool_recovery'\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(np.array([capping_flags, coupling_rates, recoveries_strands]).T, columns=columns)\n",
    "    df_capping = df.loc[df['capping'] == 'True']\n",
    "    df_no_capping = df.loc[df['capping'] ==  'False']\n",
    "\n",
    "    df_capping = df_capping.drop(['capping'], axis=1)\n",
    "    df_no_capping = df_no_capping.drop(['capping'], axis=1)\n",
    "\n",
    "    return df_capping, df_no_capping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequenced_strands_sampled = random.sample(sequenced_strands, 15000)\n",
    "len(sequenced_strands_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   coupling_rate pool_recovery\n",
      "0            0.9         0.345\n",
      "2            0.9          0.34\n",
      "4            0.9         0.335\n",
      "6          0.925         0.335\n",
      "8          0.925         0.335\n",
      "10         0.925         0.335\n",
      "12          0.95         0.335\n",
      "14          0.95          0.34\n",
      "16          0.95          0.33\n",
      "18         0.975         0.355\n",
      "20         0.975          0.35\n",
      "22         0.975         0.455\n",
      "24          0.99         0.595\n",
      "26          0.99         0.405\n",
      "28          0.99         0.365\n",
      "   coupling_rate pool_recovery\n",
      "1            0.9         0.335\n",
      "3            0.9         0.355\n",
      "5            0.9          0.35\n",
      "7          0.925         0.415\n",
      "9          0.925         0.335\n",
      "11         0.925         0.325\n",
      "13          0.95          0.33\n",
      "15          0.95          0.34\n",
      "17          0.95         0.415\n",
      "19         0.975         0.995\n",
      "21         0.975          0.92\n",
      "23         0.975          0.93\n",
      "25          0.99           1.0\n",
      "27          0.99         0.995\n",
      "29          0.99         0.675\n"
     ]
    }
   ],
   "source": [
    "\n",
    "recoveries_strands = cluster_data(original_strands=original_strands, sequenced_strands=sequenced_strands_sampled)\n",
    "df_capping, df_no_capping = post_process_results(recoveries_strands=recoveries_strands, capping_flags=capping_flags, coupling_rates=coupling_rates)\n",
    "print(df_capping)\n",
    "print(df_no_capping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Generate new file with new ids\n",
    "2. Collect Badread sequencing run\n",
    "3. Sampling statistics to understand how reads are being generated\n",
    "4. Clean orientation and make a proper strand pool to cluster\n",
    "5. Complete Experiment with growing repeats\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
