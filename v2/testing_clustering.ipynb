{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering using Edit Distance\n",
    "Trying to implement strand isolation using purely Edit Distance. Want to select the same strands together after signatures using some similarity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from aligned_clustering import conduct_align_clustering\n",
    "from utils import get_fastq_records, load_json_file, get_original_strands, get_badread_strand_id, get_recovery_percentage, create_random_strand\n",
    "import Levenshtein\n",
    "import random\n",
    "from Levenshtein import ratio, distance\n",
    "from collections import Counter\n",
    "from heirarchal_clustering import filter_junk_reads\n",
    "from seq_stat import align\n",
    "import matplotlib.pyplot as plt\n",
    "import heirarchal_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#records_original = get_fastq_records(r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\v2\\runs\\2025-01-30 21.21.00.463318\\reads_no_adapters.fastq\")\n",
    "records_original = get_fastq_records(r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\v2\\runs\\2025-01-30 21.21.00.463318\\reads_adapters.fastq\\reads_adapters.fastq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_strand_ids, coupling_rates, capping_flags, original_strands = get_original_strands(r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\v2\\runs\\2025-01-30 21.21.00.463318\\original_strands.txt\")\n",
    "\n",
    "strand_ids_synthesized = load_json_file(r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\v2\\runs\\2025-01-30 21.21.00.463318\\synthesized_uid_reference.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [i for i in records_original if get_badread_strand_id(i) in strand_ids_synthesized]\n",
    "#records = filter_junk_reads(records)\n",
    "seqs = [str(i.seq) for i in records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ID reference functions\n",
    "\n",
    "def get_badread_strand_id(record):\n",
    "    return record.description.split()[1].split(',')[0]\n",
    "\n",
    "def get_strand_reference(strand_record, strand_index=True):\n",
    "\n",
    "    strand_id = get_badread_strand_id(strand_record)\n",
    "\n",
    "    if strand_id in strand_ids_synthesized:\n",
    "        if strand_index:\n",
    "            return original_strand_ids.index(strand_ids_synthesized[strand_id])\n",
    "        else: \n",
    "            return original_strands[original_strand_ids.index(strand_ids_synthesized[strand_id])]\n",
    "    print(\"Invalid Strand ID!\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edit_distance_matrix(strands):\n",
    "    \"\"\"\n",
    "    Returns the edit distance matrix for the strands\n",
    "    O(n^2)\n",
    "    \"\"\"\n",
    "\n",
    "    n_strands = len(strands)\n",
    "    edit_distance_matrix = np.zeros([n_strands, n_strands])\n",
    "    for i in range(n_strands - 1):\n",
    "        for j in range(i + 1, n_strands):\n",
    "            edit_distance_matrix[i,j] = edit_distance_matrix[j, i] = ratio(strands[i], strands[j])\n",
    "\n",
    "    return edit_distance_matrix\n",
    "\n",
    "def calculate_centroid(strands):\n",
    "    edit_distance_matrix = get_edit_distance_matrix(strands)\n",
    "\n",
    "    distances = [sum(edit_distance_matrix[i, :]) for i in range(len(edit_distance_matrix))]\n",
    "    return strands[distances.index(min(distances))]\n",
    "\n",
    "\n",
    "def get_mean_edit_distance_cluster(edit_distance_matrix):\n",
    "    distances = [sum(edit_distance_matrix[i, :]) for i in range(len(edit_distance_matrix))]\n",
    "    return np.mean(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "287it [00:00, 392.78it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# To catch the adapters\n",
    "clusters, centroids, distance_matrices = heirarchal_clustering.cluster_trivial(seqs, similarity_threshold=0.75, use_centroids=True, analysis=True)\n",
    "clustered_seqs = [[str(records[i].seq) for i in j] for j in clusters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levenshtien edit distance works pretty well. That's my metric. Kmeans works for now. I'll bring down junk reads etc, remove adapters, and test it again to see how well aggregation works.\n",
    "Maybe try DBscan with Levenshtien distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target           25 TTTCAGTCTGTGCGAGTGACAGATCAATCCCA-CCCGCAGGTTCCTTAGTCAGATGTAAA\n",
      "                  0 ||||||||||||||||||||||||||||||||-|||||||||||||||||||||||||||\n",
      "query             0 TTTCAGTCTGTGCGAGTGACAGATCAATCCCACCCCGCAGGTTCCTTAGTCAGATGTAAA\n",
      "\n",
      "target           84 TACGACCCGGGTGTGAGTACTGTACTGAGTACTCAGTGGAACCCTCTGGAGAGGGAGCTT\n",
      "                 60 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query            60 TACGACCCGGGTGTGAGTACTGTACTGAGTACTCAGTGGAACCCTCTGGAGAGGGAGCTT\n",
      "\n",
      "target          144 GCACATTGAAACAAATCATTCTTCACCCATTACGGAGTCCAGGCGCTCGTAGCTGGGCAC\n",
      "                120 ||||||||||||||||||||||||||||||||||||||||||||||||||||||-|||||\n",
      "query           120 GCACATTGAAACAAATCATTCTTCACCCATTACGGAGTCCAGGCGCTCGTAGCT-GGCAC\n",
      "\n",
      "target          204 GCTTGCCGTAATAAGCGAACA 225\n",
      "                180 ||||||||||||||||||||| 201\n",
      "query           179 GCTTGCCGTAATAAGCGAACA 200\n",
      "\n",
      "ATGTACTTCGTTCAGTTACGTATTCTTTCAGTCTGTGCGAGTGACAGATCAATCCCACCCGCAGGTTCCTTAGTCAGATGTAAATACGACCCGGGTGTGAGTACTGTACTGAGTACTCAGTGGAACCCTCTGGAGAGGGAGCTTGCACATTGAAACAAATCATTCTTCACCCATTACGGAGTCCAGGCGCTCGTAGCTGGGCACGCTTGCCGTAATAAGCGAACA\n",
      "TTTCAGTCTGTGCGAGTGACAGATCAATCCCACCCCGCAGGTTCCTTAGTCAGATGTAAATACGACCCGGGTGTGAGTACTGTACTGAGTACTCAGTGGAACCCTCTGGAGAGGGAGCTTGCACATTGAAACAAATCATTCTTCACCCATTACGGAGTCCAGGCGCTCGTAGCTGGCACGCTTGCCGTAATAAGCGAACA\n",
      "\n",
      "target           15 GTTTCGTCAACGTAATGAAGGACCTGGAACTTCCATCGCGCAGTAGGCCATCATAG--CC\n",
      "                  0 |||||||||||||||||-||||||||||||||||||||||||||||||||||||||--||\n",
      "query             0 GTTTCGTCAACGTAATG-AGGACCTGGAACTTCCATCGCGCAGTAGGCCATCATAGCCCC\n",
      "\n",
      "target           73 TAATTACCTAAGGTACGAGCCGCAAAGCACTAGCGCCCTACAAGGGCTAAGTTCTATCTC\n",
      "                 60 |.||||||||||||||||||||||.|||||||||||||||||||||||||||||||||||\n",
      "query            59 TGATTACCTAAGGTACGAGCCGCAGAGCACTAGCGCCCTACAAGGGCTAAGTTCTATCTC\n",
      "\n",
      "target          133 TAGACCTCGAGCGACGCTCAGTGTCCATGTGTGCAGTTATGTAAGACGGGCCTACAGGAT\n",
      "                120 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query           119 TAGACCTCGAGCGACGCTCAGTGTCCATGTGTGCAGTTATGTAAGACGGGCCTACAGGAT\n",
      "\n",
      "target          193 TCAGCCCTCAGCCCATTGCCT 214\n",
      "                180 ||||||||||||||||||||| 201\n",
      "query           179 TCAGCCCTCAGCCCATTGCCT 200\n",
      "\n",
      "CAGTTGCGTATTGCTGTTTCGTCAACGTAATGAAGGACCTGGAACTTCCATCGCGCAGTAGGCCATCATAGCCTAATTACCTAAGGTACGAGCCGCAAAGCACTAGCGCCCTACAAGGGCTAAGTTCTATCTCTAGACCTCGAGCGACGCTCAGTGTCCATGTGTGCAGTTATGTAAGACGGGCCTACAGGATTCAGCCCTCAGCCCATTGCCT\n",
      "GTTTCGTCAACGTAATGAGGACCTGGAACTTCCATCGCGCAGTAGGCCATCATAGCCCCTGATTACCTAAGGTACGAGCCGCAGAGCACTAGCGCCCTACAAGGGCTAAGTTCTATCTCTAGACCTCGAGCGACGCTCAGTGTCCATGTGTGCAGTTATGTAAGACGGGCCTACAGGATTCAGCCCTCAGCCCATTGCCT\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "target           24 GAAATCCTCTAGATCGAAGCCTGTCCTAGGATCAGGCCGAAGCGGTAAGAAAAATTCGGG\n",
      "                  0 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||\n",
      "query             0 GAAATCCTCTAGATCGAAGCCTGTCCTAGGATCAGGCCGAAGCGGTAAGAAAAATTCGGG\n",
      "\n",
      "target           84 TAAATGCGTGTGCATCAACATTTCGTTTTCAGAACCAATATT-CCGCGCCGGCTGCGACT\n",
      "                 60 |||||||||||||||||||||||||||||||-||||||||||-|||||||||||||||||\n",
      "query            60 TAAATGCGTGTGCATCAACATTTCGTTTTCA-AACCAATATTCCCGCGCCGGCTGCGACT\n",
      "\n",
      "target          143 GTCATCAAGACTAAAGACACTGCTCATTCGTT---CGTAGTTTAATTAGT-GAGCGGAAA\n",
      "                120 ||||||||||||||||||||||||||||||||---|--|||||||||.||-|||||||||\n",
      "query           119 GTCATCAAGACTAAAGACACTGCTCATTCGTTAGCC--AGTTTAATTGGTGGAGCGGAAA\n",
      "\n",
      "target          199 GCAAATGTGACCTATGGTGATAT 222\n",
      "                180 ||||||||||||||||||||||| 203\n",
      "query           177 GCAAATGTGACCTATGGTGATAT 200\n",
      "\n",
      "TACTTCGTTCAGTTACGTATTGCTGAAATCCTCTAGATCGAAGCCTGTCCTAGGATCAGGCCGAAGCGGTAAGAAAAATTCGGGTAAATGCGTGTGCATCAACATTTCGTTTTCAGAACCAATATTCCGCGCCGGCTGCGACTGTCATCAAGACTAAAGACACTGCTCATTCGTTCGTAGTTTAATTAGTGAGCGGAAAGCAAATGTGACCTATGGTGATATGCAATA\n",
      "GAAATCCTCTAGATCGAAGCCTGTCCTAGGATCAGGCCGAAGCGGTAAGAAAAATTCGGGTAAATGCGTGTGCATCAACATTTCGTTTTCAAACCAATATTCCCGCGCCGGCTGCGACTGTCATCAAGACTAAAGACACTGCTCATTCGTTAGCCAGTTTAATTGGTGGAGCGGAAAGCAAATGTGACCTATGGTGATAT\n",
      "\n",
      "target           19 TCGTCCTCAACGGCAGGCGATAAGCACACAATGGCAAAGTCCGAGCATAAGCTCTCACAT\n",
      "                  0 ||||||||||||||||||||||||||||||||||||||||||||||||||||||||||.|\n",
      "query             0 TCGTCCTCAACGGCAGGCGATAAGCACACAATGGCAAAGTCCGAGCATAAGCTCTCACGT\n",
      "\n",
      "target           79 AAAAAACCCAGGAGGTCTGTTTAGTGACCTCTAATAAAACATAGCATGGTAGGCAGCATT\n",
      "                 60 |||||||||||||||||||.||||||||||||||||||||||||||||||||||||||||\n",
      "query            60 AAAAAACCCAGGAGGTCTGCTTAGTGACCTCTAATAAAACATAGCATGGTAGGCAGCATT\n",
      "\n",
      "target          139 TGTGCTGAACACCCTTGATT-CCGCAGTTCCTGTATA-TGCTTATACCCCGGAGTTTGTC\n",
      "                120 ||||||||||||||||||||-||||||||||||||||-||||||||||||||||||||||\n",
      "query           120 TGTGCTGAACACCCTTGATTCCCGCAGTTCCTGTATATTGCTTATACCCCGGAGTTTGTC\n",
      "\n",
      "target          197 GTCTACTGCTAGGAGCCGTG 217\n",
      "                180 |||||||||||||||||||| 200\n",
      "query           180 GTCTACTGCTAGGAGCCGTG 200\n",
      "\n",
      "CGTTCAGTTACGTATTGCTTCGTCCTCAACGGCAGGCGATAAGCACACAATGGCAAAGTCCGAGCATAAGCTCTCACATAAAAAACCCAGGAGGTCTGTTTAGTGACCTCTAATAAAACATAGCATGGTAGGCAGCATTTGTGCTGAACACCCTTGATTCCGCAGTTCCTGTATATGCTTATACCCCGGAGTTTGTCGTCTACTGCTAGGAGCCGTG\n",
      "TCGTCCTCAACGGCAGGCGATAAGCACACAATGGCAAAGTCCGAGCATAAGCTCTCACGTAAAAAACCCAGGAGGTCTGCTTAGTGACCTCTAATAAAACATAGCATGGTAGGCAGCATTTGTGCTGAACACCCTTGATTCCCGCAGTTCCTGTATATTGCTTATACCCCGGAGTTTGTCGTCTACTGCTAGGAGCCGTG\n",
      "\n",
      "target           19 TGACAACTGAAATTCCAGCGAAGCGCGGGCATGACATAGCACCCGAACCCATTAAATTCT\n",
      "                  0 |||||||||||||||||||||||||||||||||||||||||||||||||||-||||||||\n",
      "query             0 TGACAACTGAAATTCCAGCGAAGCGCGGGCATGACATAGCACCCGAACCCA-TAAATTCT\n",
      "\n",
      "target           79 GCTACCACAGTATCGTAGAACAACTAAATTCGGTGACGTGCTTATAGCGACCGCGTACAC\n",
      "                 60 ||||||||||||||||||||||||||||-|||||||||||||||||||||||||||||||\n",
      "query            59 GCTACCACAGTATCGTAGAACAACTAAA-TCGGTGACGTGCTTATAGCGACCGCGTACAC\n",
      "\n",
      "target          139 GCCTCATGGCCACACGCGAGCCCAGA-CGAGTCACGTAGTTTACGGTCCCTAAGTTTGTT\n",
      "                120 ||||||||||||||||||||||||||-|||||||||||.|||||||||||||||||||||\n",
      "query           118 GCCTCATGGCCACACGCGAGCCCAGAGCGAGTCACGTAATTTACGGTCCCTAAGTTTGTT\n",
      "\n",
      "target          198 GTTTTTACCAGCAGGTACAATC 220\n",
      "                180 |||||||||||||||||||||| 202\n",
      "query           178 GTTTTTACCAGCAGGTACAATC 200\n",
      "\n",
      "CGTTCAGTTACGTATTGCTTGACAACTGAAATTCCAGCGAAGCGCGGGCATGACATAGCACCCGAACCCATTAAATTCTGCTACCACAGTATCGTAGAACAACTAAATTCGGTGACGTGCTTATAGCGACCGCGTACACGCCTCATGGCCACACGCGAGCCCAGACGAGTCACGTAGTTTACGGTCCCTAAGTTTGTTGTTTTTACCAGCAGGTACAATC\n",
      "TGACAACTGAAATTCCAGCGAAGCGCGGGCATGACATAGCACCCGAACCCATAAATTCTGCTACCACAGTATCGTAGAACAACTAAATCGGTGACGTGCTTATAGCGACCGCGTACACGCCTCATGGCCACACGCGAGCCCAGAGCGAGTCACGTAATTTACGGTCCCTAAGTTTGTTGTTTTTACCAGCAGGTACAATC\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And then merge and validate for top 5\n",
    "\n",
    "original_strand_guessed_best = []\n",
    "\n",
    "for ind, i in enumerate(centroids):\n",
    "    \n",
    "    best_guessed = 0\n",
    "    best_rec = 0.0\n",
    "    for k, original_strand in enumerate(original_strands):\n",
    "        rec = ratio(i, original_strand)\n",
    "\n",
    "        if rec > best_rec:\n",
    "            best_guessed = k\n",
    "            best_rec = rec\n",
    "\n",
    "    original_strand_guessed_best.append(best_guessed)\n",
    "    if best_rec > 0.9:\n",
    "        print(align(i, original_strands[best_guessed], identity=False))\n",
    "        print(i)\n",
    "        print(original_strands[best_guessed])\n",
    "    #print(f\"{best_guessed} {best_rec} recovered by {ind}\".format())\n",
    "    #print(len(i))\n",
    "\n",
    "    #print(f\"{len(clusters[ind])} elements in the cluster\")\n",
    "    #print(f\"{np.mean([len(i) for i in clustered_seqs[ind]])} mean length of strand in cluster\")\n",
    "    #print(f\"{np.std([len(i) for i in clustered_seqs[ind]])} mean std of strand in cluster\")\n",
    "    #print(f\"{get_mean_edit_distance_cluster(distance_matrices[ind])} mean edit distance within cluster\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:00, 1182.65it/s]\n"
     ]
    }
   ],
   "source": [
    "clusters_2 = heirarchal_clustering.cluster_trivial(centroids, similarity_threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_seqs.sort(key=len, reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.5110294117647058 recovered by 0\n",
      "\n",
      "3 1.0 recovered by 1\n",
      "\n",
      "1 1.0 recovered by 2\n",
      "\n",
      "0 0.5243445692883895 recovered by 3\n",
      "\n",
      "4 1.0 recovered by 4\n",
      "\n",
      "2 1.0 recovered by 5\n",
      "\n",
      "0 0.5183823529411765 recovered by 6\n",
      "\n",
      "0 0.4856115107913669 recovered by 7\n",
      "\n",
      "0 1.0 recovered by 8\n",
      "\n",
      "4 0.5054545454545455 recovered by 9\n",
      "\n",
      "1 0.9900497512437811 recovered by 10\n",
      "\n",
      "4 0.46875 recovered by 11\n",
      "\n",
      "1 0.3701657458563536 recovered by 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And then merge and validate for top 5\n",
    "\n",
    "original_strand_guessed_best = []\n",
    "\n",
    "for i in range(len(clustered_seqs)):\n",
    "    if len(clustered_seqs) > 15:\n",
    "        guess = heirarchal_clustering.make_prediction(clustered_seqs[i], sample_size=15)\n",
    "    else:\n",
    "        guess = heirarchal_clustering.make_prediction(clustered_seqs[i], sample_size=len(clustered_seqs[i]))\n",
    "    \n",
    "    best_guessed = 0\n",
    "    best_rec = 0.0\n",
    "    for k, original_strand in enumerate(original_strands):\n",
    "        rec = get_recovery_percentage(guess, original_strand)\n",
    "        rec = align(guess, original_strand)\n",
    "\n",
    "        if rec > best_rec:\n",
    "            best_guessed = k\n",
    "            best_rec = rec\n",
    "\n",
    "    original_strand_guessed_best.append(best_guessed)\n",
    "    print(f\"{best_guessed} {best_rec} recovered by {i}\".format())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs further testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
