{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering using Edit Distance\n",
    "Trying to implement strand isolation using purely Edit Distance. Want to select the same strands together after signatures using some similarity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from aligned_clustering import conduct_align_clustering\n",
    "from utils import get_fastq_records, load_json_file, get_original_strands, get_badread_strand_id, get_recovery_percentage, create_random_strand, len_histogram, get_sort_by_sublists_length\n",
    "import Levenshtein\n",
    "import random\n",
    "from Levenshtein import ratio, distance\n",
    "from collections import Counter\n",
    "from seq_stat import align\n",
    "import matplotlib.pyplot as plt\n",
    "import heirarchal_clustering\n",
    "import strand_filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "296it [00:00, 24523.73it/s]\n"
     ]
    }
   ],
   "source": [
    "#records_original = get_fastq_records(r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\v2\\runs\\2025-01-30 21.21.00.463318\\reads_no_adapters.fastq\")\n",
    "records_original = get_fastq_records(r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\v2\\runs\\2025-01-30 21.21.00.463318\\reads_adapters.fastq\\reads_adapters.fastq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_strand_ids, coupling_rates, capping_flags, original_strands = get_original_strands(r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\v2\\runs\\2025-01-30 21.21.00.463318\\original_strands.txt\")\n",
    "\n",
    "strand_ids_synthesized = load_json_file(r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\v2\\runs\\2025-01-30 21.21.00.463318\\synthesized_uid_reference.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [i for i in records_original if get_badread_strand_id(i) in strand_ids_synthesized]\n",
    "#records = filter_junk_reads(records)\n",
    "seqs = [str(i.seq) for i in records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ID reference functions\n",
    "\n",
    "def get_badread_strand_id(record):\n",
    "    return record.description.split()[1].split(',')[0]\n",
    "\n",
    "def get_strand_reference(strand_record, strand_index=True):\n",
    "\n",
    "    strand_id = get_badread_strand_id(strand_record)\n",
    "\n",
    "    if strand_id in strand_ids_synthesized:\n",
    "        if strand_index:\n",
    "            return original_strand_ids.index(strand_ids_synthesized[strand_id])\n",
    "        else: \n",
    "            return original_strands[original_strand_ids.index(strand_ids_synthesized[strand_id])]\n",
    "    print(\"Invalid Strand ID!\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edit_distance_matrix(strands):\n",
    "    \"\"\"\n",
    "    Returns the edit distance matrix for the strands\n",
    "    O(n^2)\n",
    "    \"\"\"\n",
    "\n",
    "    n_strands = len(strands)\n",
    "    edit_distance_matrix = np.zeros([n_strands, n_strands])\n",
    "    for i in range(n_strands - 1):\n",
    "        for j in range(i + 1, n_strands):\n",
    "            edit_distance_matrix[i,j] = edit_distance_matrix[j, i] = ratio(strands[i], strands[j])\n",
    "\n",
    "    return edit_distance_matrix\n",
    "\n",
    "def calculate_centroid(strands):\n",
    "    edit_distance_matrix = get_edit_distance_matrix(strands)\n",
    "\n",
    "    distances = [sum(edit_distance_matrix[i, :]) for i in range(len(edit_distance_matrix))]\n",
    "    return strands[distances.index(min(distances))]\n",
    "\n",
    "\n",
    "def get_mean_edit_distance_cluster(edit_distance_matrix):\n",
    "    distances = [sum(edit_distance_matrix[i, :]) for i in range(len(edit_distance_matrix))]\n",
    "    return np.mean(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total strands 287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "287it [00:00, 11955.76it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# To catch the adapters\n",
    "clusters, centroids = heirarchal_clustering.cluster_trivial(seqs, similarity_threshold=0.97, use_centroids=False, analysis=False)\n",
    "clustered_seqs = [[str(records[i].seq) for i in j] for j in clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total strands 287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "287it [00:00, 72259.15it/s]\n"
     ]
    }
   ],
   "source": [
    "clusters2, centroids2 = heirarchal_clustering.cluster_trivial(seqs, similarity_threshold=0.90, use_centroids=False, analysis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = get_sort_by_sublists_length(clusters)\n",
    "sorted_clusters = [clusters[i] for i in indices]\n",
    "sorted_centroids = [centroids[i] for i in indices]\n",
    "sorted_clustered_seqs = [clustered_seqs[i] for i in indices]\n",
    "\n",
    "centroids = sorted_centroids\n",
    "clusters = sorted_clusters\n",
    "clustered_seqs = sorted_clustered_seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levenshtien edit distance works pretty well. That's my metric. Kmeans works for now. I'll bring down junk reads etc, remove adapters, and test it again to see how well aggregation works.\n",
    "Maybe try DBscan with Levenshtien distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.9299065420560748 recovered by 0\n",
      "7 elements in the cluster\n",
      "\n",
      "1 0.6299212598425197 recovered by 1\n",
      "5 elements in the cluster\n",
      "\n",
      "4 0.6616541353383458 recovered by 2\n",
      "5 elements in the cluster\n",
      "\n",
      "0 0.6697892271662764 recovered by 3\n",
      "5 elements in the cluster\n",
      "\n",
      "0 0.6745843230403801 recovered by 4\n",
      "4 elements in the cluster\n",
      "\n",
      "0 0.9248826291079812 recovered by 5\n",
      "4 elements in the cluster\n",
      "\n",
      "2 0.9245283018867925 recovered by 6\n",
      "4 elements in the cluster\n",
      "\n",
      "1 0.6439024390243903 recovered by 7\n",
      "4 elements in the cluster\n",
      "\n",
      "4 0.9408983451536643 recovered by 8\n",
      "4 elements in the cluster\n",
      "\n",
      "1 0.92018779342723 recovered by 9\n",
      "4 elements in the cluster\n",
      "\n",
      "1 0.9314420803782506 recovered by 10\n",
      "4 elements in the cluster\n",
      "\n",
      "3 0.6603325415676959 recovered by 11\n",
      "3 elements in the cluster\n",
      "\n",
      "4 0.6570048309178744 recovered by 12\n",
      "3 elements in the cluster\n",
      "\n",
      "4 0.9705882352941176 recovered by 13\n",
      "3 elements in the cluster\n",
      "\n",
      "3 0.6509433962264151 recovered by 14\n",
      "3 elements in the cluster\n",
      "\n",
      "3 0.6509433962264151 recovered by 15\n",
      "3 elements in the cluster\n",
      "\n",
      "1 0.9358669833729216 recovered by 16\n",
      "3 elements in the cluster\n",
      "\n",
      "4 0.9609756097560975 recovered by 17\n",
      "3 elements in the cluster\n",
      "\n",
      "0 0.6348448687350836 recovered by 18\n",
      "3 elements in the cluster\n",
      "\n",
      "2 0.9406175771971497 recovered by 19\n",
      "3 elements in the cluster\n",
      "\n",
      "4 0.6542056074766356 recovered by 20\n",
      "3 elements in the cluster\n",
      "\n",
      "3 0.9797979797979798 recovered by 21\n",
      "3 elements in the cluster\n",
      "\n",
      "1 0.6498855835240275 recovered by 22\n",
      "3 elements in the cluster\n",
      "\n",
      "1 0.9563106796116505 recovered by 23\n",
      "2 elements in the cluster\n",
      "\n",
      "3 0.9582309582309583 recovered by 24\n",
      "2 elements in the cluster\n",
      "\n",
      "0 0.6582914572864322 recovered by 25\n",
      "2 elements in the cluster\n",
      "\n",
      "4 0.6352941176470588 recovered by 26\n",
      "2 elements in the cluster\n",
      "\n",
      "0 0.6619047619047619 recovered by 27\n",
      "2 elements in the cluster\n",
      "\n",
      "1 0.9774436090225564 recovered by 28\n",
      "2 elements in the cluster\n",
      "\n",
      "3 0.6525821596244131 recovered by 29\n",
      "2 elements in the cluster\n",
      "\n",
      "4 0.6633906633906634 recovered by 30\n",
      "2 elements in the cluster\n",
      "\n",
      "0 0.6635071090047393 recovered by 31\n",
      "2 elements in the cluster\n",
      "\n",
      "0 0.6604651162790698 recovered by 32\n",
      "2 elements in the cluster\n",
      "\n",
      "2 0.9317647058823529 recovered by 33\n",
      "2 elements in the cluster\n",
      "\n",
      "2 0.9558823529411765 recovered by 34\n",
      "2 elements in the cluster\n",
      "\n",
      "0 0.6618705035971223 recovered by 35\n",
      "2 elements in the cluster\n",
      "\n",
      "3 0.6587677725118484 recovered by 36\n",
      "2 elements in the cluster\n",
      "\n",
      "2 0.9403341288782816 recovered by 37\n",
      "2 elements in the cluster\n",
      "\n",
      "2 0.9682151589242054 recovered by 38\n",
      "2 elements in the cluster\n",
      "\n",
      "4 0.6516290726817042 recovered by 39\n",
      "2 elements in the cluster\n",
      "\n",
      "0 0.9828009828009828 recovered by 40\n",
      "2 elements in the cluster\n",
      "\n",
      "0 0.6549118387909321 recovered by 41\n",
      "2 elements in the cluster\n",
      "\n",
      "4 0.6372093023255814 recovered by 42\n",
      "2 elements in the cluster\n",
      "\n",
      "0 0.9801980198019802 recovered by 43\n",
      "2 elements in the cluster\n",
      "\n",
      "0 0.6683046683046683 recovered by 44\n",
      "2 elements in the cluster\n",
      "\n",
      "0 0.9349397590361446 recovered by 45\n",
      "2 elements in the cluster\n",
      "\n",
      "0 0.8990825688073394 recovered by 46\n",
      "2 elements in the cluster\n",
      "\n",
      "4 0.6401985111662531 recovered by 47\n",
      "2 elements in the cluster\n",
      "\n",
      "3 0.9658536585365853 recovered by 48\n",
      "2 elements in the cluster\n",
      "\n",
      "0 0.6585956416464891 recovered by 49\n",
      "2 elements in the cluster\n",
      "\n",
      "0 0.9248826291079812 recovered by 50\n",
      "2 elements in the cluster\n",
      "\n",
      "4 0.6486486486486487 recovered by 51\n",
      "2 elements in the cluster\n",
      "\n",
      "0 0.6732186732186732 recovered by 52\n",
      "2 elements in the cluster\n",
      "\n",
      "0 0.6585365853658536 recovered by 53\n",
      "2 elements in the cluster\n",
      "\n",
      "4 0.9850746268656716 recovered by 54\n",
      "2 elements in the cluster\n",
      "\n",
      "3 0.9443099273607748 recovered by 55\n",
      "2 elements in the cluster\n",
      "\n",
      "3 0.937799043062201 recovered by 56\n",
      "2 elements in the cluster\n",
      "\n",
      "4 0.657210401891253 recovered by 57\n",
      "2 elements in the cluster\n",
      "\n",
      "4 0.9219858156028369 recovered by 58\n",
      "2 elements in the cluster\n",
      "\n",
      "4 0.9586374695863747 recovered by 59\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.9408983451536643 recovered by 60\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.6426858513189448 recovered by 61\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.9311163895486936 recovered by 62\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.642156862745098 recovered by 63\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.9539951573849879 recovered by 64\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.9400479616306955 recovered by 65\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6666666666666667 recovered by 66\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.657074340527578 recovered by 67\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6401869158878505 recovered by 68\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.9493975903614458 recovered by 69\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.656934306569343 recovered by 70\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.6509433962264151 recovered by 71\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6431924882629108 recovered by 72\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.8967136150234741 recovered by 73\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.6435643564356436 recovered by 74\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.8995433789954338 recovered by 75\n",
      "1 elements in the cluster\n",
      "\n",
      "2 0.982367758186398 recovered by 76\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.6390243902439025 recovered by 77\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.6586538461538461 recovered by 78\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.9383886255924171 recovered by 79\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.9603960396039604 recovered by 80\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6462264150943396 recovered by 81\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.941747572815534 recovered by 82\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.9653465346534653 recovered by 83\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.9563106796116505 recovered by 84\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.6584766584766585 recovered by 85\n",
      "1 elements in the cluster\n",
      "\n",
      "2 0.9095238095238095 recovered by 86\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6602870813397129 recovered by 87\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.9323671497584541 recovered by 88\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.92018779342723 recovered by 89\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.9775561097256857 recovered by 90\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6538461538461539 recovered by 91\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6666666666666667 recovered by 92\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6386946386946387 recovered by 93\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.9656862745098039 recovered by 94\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.9824561403508771 recovered by 95\n",
      "1 elements in the cluster\n",
      "\n",
      "2 0.9542168674698795 recovered by 96\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.6487804878048781 recovered by 97\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.6566416040100251 recovered by 98\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6298076923076923 recovered by 99\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6633906633906634 recovered by 100\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.6365795724465558 recovered by 101\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.9655172413793104 recovered by 102\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6555023923444976 recovered by 103\n",
      "1 elements in the cluster\n",
      "\n",
      "2 0.9493975903614458 recovered by 104\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.6634615384615384 recovered by 105\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.6432160804020101 recovered by 106\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.9825436408977556 recovered by 107\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.9824561403508771 recovered by 108\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.9414634146341463 recovered by 109\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.9539951573849879 recovered by 110\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.9471153846153846 recovered by 111\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.9448441247002398 recovered by 112\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.6603325415676959 recovered by 113\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.987468671679198 recovered by 114\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.6533665835411471 recovered by 115\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.6510538641686183 recovered by 116\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.9611650485436893 recovered by 117\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.9471153846153846 recovered by 118\n",
      "1 elements in the cluster\n",
      "\n",
      "2 0.9849246231155779 recovered by 119\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6635514018691588 recovered by 120\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.6602870813397129 recovered by 121\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.6651053864168619 recovered by 122\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.6507177033492824 recovered by 123\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.92018779342723 recovered by 124\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6384976525821596 recovered by 125\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.9129411764705883 recovered by 126\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6601941747572815 recovered by 127\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.9230769230769231 recovered by 128\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.6356968215158925 recovered by 129\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6634146341463414 recovered by 130\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.9270588235294117 recovered by 131\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.9680589680589681 recovered by 132\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.6519607843137255 recovered by 133\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.9223529411764706 recovered by 134\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.6448362720403022 recovered by 135\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.9523809523809523 recovered by 136\n",
      "1 elements in the cluster\n",
      "\n",
      "2 0.92018779342723 recovered by 137\n",
      "1 elements in the cluster\n",
      "\n",
      "2 0.9230769230769231 recovered by 138\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.65 recovered by 139\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.9849246231155779 recovered by 140\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6519607843137255 recovered by 141\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6365795724465558 recovered by 142\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6650602409638554 recovered by 143\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.9408983451536643 recovered by 144\n",
      "1 elements in the cluster\n",
      "\n",
      "2 0.9542168674698795 recovered by 145\n",
      "1 elements in the cluster\n",
      "\n",
      "2 0.9176470588235294 recovered by 146\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.945273631840796 recovered by 147\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.9012048192771085 recovered by 148\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.6572769953051643 recovered by 149\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.9609756097560975 recovered by 150\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.6557377049180328 recovered by 151\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.9176470588235294 recovered by 152\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.6419753086419753 recovered by 153\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6477541371158393 recovered by 154\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.6619718309859155 recovered by 155\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.9278846153846154 recovered by 156\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6538461538461539 recovered by 157\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6459330143540669 recovered by 158\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.9468599033816425 recovered by 159\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6582278481012658 recovered by 160\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.9355608591885441 recovered by 161\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.6287425149700598 recovered by 162\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.9414634146341463 recovered by 163\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.649746192893401 recovered by 164\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6519607843137255 recovered by 165\n",
      "1 elements in the cluster\n",
      "\n",
      "2 0.9176470588235294 recovered by 166\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.9186602870813397 recovered by 167\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.5054945054945055 recovered by 168\n",
      "1 elements in the cluster\n",
      "\n",
      "2 0.9234567901234568 recovered by 169\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.9168646080760094 recovered by 170\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6700251889168766 recovered by 171\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6666666666666667 recovered by 172\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.6524822695035462 recovered by 173\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.6487804878048781 recovered by 174\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.6555819477434679 recovered by 175\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.9176470588235294 recovered by 176\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.9267139479905437 recovered by 177\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.9234449760765551 recovered by 178\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.8981481481481481 recovered by 179\n",
      "1 elements in the cluster\n",
      "\n",
      "3 0.9358669833729216 recovered by 180\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.9516908212560387 recovered by 181\n",
      "1 elements in the cluster\n",
      "\n",
      "4 0.6602870813397129 recovered by 182\n",
      "1 elements in the cluster\n",
      "\n",
      "2 0.9209302325581395 recovered by 183\n",
      "1 elements in the cluster\n",
      "\n",
      "1 0.642156862745098 recovered by 184\n",
      "1 elements in the cluster\n",
      "\n",
      "2 0.9777777777777777 recovered by 185\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.657210401891253 recovered by 186\n",
      "1 elements in the cluster\n",
      "\n",
      "0 0.6585956416464891 recovered by 187\n",
      "1 elements in the cluster\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And then merge and validate for top 5\n",
    "\n",
    "original_strand_guessed_best = []\n",
    "\n",
    "for ind, i in enumerate(centroids):\n",
    "    \n",
    "    best_guessed = 0\n",
    "    best_rec = 0.0\n",
    "    for k, original_strand in enumerate(original_strands):\n",
    "        rec = ratio(i, original_strand)\n",
    "\n",
    "        if rec > best_rec:\n",
    "            best_guessed = k\n",
    "            best_rec = rec\n",
    "\n",
    "    original_strand_guessed_best.append(best_guessed)\n",
    "    #if best_rec > 0.9:\n",
    "    #    print(i)\n",
    "    #    print(original_strands[best_guessed])\n",
    "    print(f\"{best_guessed} {best_rec} recovered by {ind}\".format())\n",
    "    #print(len(i))\n",
    "\n",
    "    print(f\"{len(clusters[ind])} elements in the cluster\")\n",
    "    #print(f\"{np.mean([len(i) for i in clustered_seqs[ind]])} mean length of strand in cluster\")\n",
    "    #print(f\"{np.std([len(i) for i in clustered_seqs[ind]])} mean std of strand in cluster\")\n",
    "    #print(f\"{get_mean_edit_distance_cluster(distance_matrices[ind])} mean edit distance within cluster\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:00, 1182.65it/s]\n"
     ]
    }
   ],
   "source": [
    "clusters_2 = heirarchal_clustering.cluster_trivial(centroids, similarity_threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_seqs.sort(key=len, reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.5110294117647058 recovered by 0\n",
      "\n",
      "3 1.0 recovered by 1\n",
      "\n",
      "1 1.0 recovered by 2\n",
      "\n",
      "0 0.5243445692883895 recovered by 3\n",
      "\n",
      "4 1.0 recovered by 4\n",
      "\n",
      "2 1.0 recovered by 5\n",
      "\n",
      "0 0.5183823529411765 recovered by 6\n",
      "\n",
      "0 0.4856115107913669 recovered by 7\n",
      "\n",
      "0 1.0 recovered by 8\n",
      "\n",
      "4 0.5054545454545455 recovered by 9\n",
      "\n",
      "1 0.9900497512437811 recovered by 10\n",
      "\n",
      "4 0.46875 recovered by 11\n",
      "\n",
      "1 0.3701657458563536 recovered by 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And then merge and validate for top 5\n",
    "\n",
    "original_strand_guessed_best = []\n",
    "\n",
    "for i in range(len(clustered_seqs)):\n",
    "    if len(clustered_seqs) > 15:\n",
    "        guess = heirarchal_clustering.make_prediction(clustered_seqs[i], sample_size=15)\n",
    "    else:\n",
    "        guess = heirarchal_clustering.make_prediction(clustered_seqs[i], sample_size=len(clustered_seqs[i]))\n",
    "    \n",
    "    best_guessed = 0\n",
    "    best_rec = 0.0\n",
    "    for k, original_strand in enumerate(original_strands):\n",
    "        rec = get_recovery_percentage(guess, original_strand)\n",
    "        rec = align(guess, original_strand)\n",
    "\n",
    "        if rec > best_rec:\n",
    "            best_guessed = k\n",
    "            best_rec = rec\n",
    "\n",
    "    original_strand_guessed_best.append(best_guessed)\n",
    "    print(f\"{best_guessed} {best_rec} recovered by {i}\".format())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs further testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
