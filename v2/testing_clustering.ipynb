{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering using Hash functions\n",
    "Trying to implement strand isolation using purely Hash functions. Want to select the same strands together after signatures using some similarity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from aligned_clustering import conduct_align_clustering\n",
    "from utils import get_fastq_records, load_json_file, get_original_strands, get_badread_strand_id, get_recovery_percentage, create_random_strand\n",
    "import Levenshtein\n",
    "import random\n",
    "from Levenshtein import ratio\n",
    "from collections import Counter\n",
    "from heirarchal_clustering import filter_junk_reads\n",
    "from seq_stat import align\n",
    "import matplotlib.pyplot as plt\n",
    "import heirarchal_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#records_original = get_fastq_records(r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\v2\\runs\\2025-01-30 21.21.00.463318\\reads_no_adapters.fastq\")\n",
    "records_original = get_fastq_records(r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\v2\\runs\\2025-01-30 21.21.00.463318\\reads_adapters.fastq\\reads_adapters.fastq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_strand_ids, coupling_rates, capping_flags, original_strands = get_original_strands(r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\v2\\runs\\2025-01-30 21.21.00.463318\\original_strands.txt\")\n",
    "\n",
    "strand_ids_synthesized = load_json_file(r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\v2\\runs\\2025-01-30 21.21.00.463318\\synthesized_uid_reference.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [i for i in records_original if get_badread_strand_id(i) in strand_ids_synthesized]\n",
    "#records = filter_junk_reads(records)\n",
    "seqs = [str(i.seq) for i in records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "287it [00:00, 40989.01it/s]\n"
     ]
    }
   ],
   "source": [
    "clusters = heirarchal_clustering.cluster_trivial(seqs, similarity_threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levenshtien edit distance works pretty well. That's my metric. Kmeans works for now. I'll bring down junk reads etc, remove adapters, and test it again to see how well aggregation works.\n",
    "Maybe try DBscan with Levenshtien distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clustered_seqs = []\n",
    "for j in clusters:\n",
    "    clustered_seqs.append([str(records[ind].seq) for ind in clusters[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_seqs.sort(key=len, reverse=True)\n",
    "top_5 = clustered_seqs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.22 recovered by 0\n",
      "1 0.25 recovered by 0\n",
      "2 0.305 recovered by 0\n",
      "3 0.26 recovered by 0\n",
      "4 0.225 recovered by 0\n",
      "\n",
      "0 0.3 recovered by 1\n",
      "1 0.24 recovered by 1\n",
      "2 0.26 recovered by 1\n",
      "3 0.215 recovered by 1\n",
      "4 0.275 recovered by 1\n",
      "\n",
      "0 0.28 recovered by 2\n",
      "1 0.235 recovered by 2\n",
      "2 0.29 recovered by 2\n",
      "3 0.26 recovered by 2\n",
      "4 0.28 recovered by 2\n",
      "\n",
      "0 0.32 recovered by 3\n",
      "1 0.24 recovered by 3\n",
      "2 0.28 recovered by 3\n",
      "3 0.315 recovered by 3\n",
      "4 0.2 recovered by 3\n",
      "\n",
      "0 0.26 recovered by 4\n",
      "1 0.255 recovered by 4\n",
      "2 0.245 recovered by 4\n",
      "3 0.275 recovered by 4\n",
      "4 0.255 recovered by 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And then merge and validate for top 5\n",
    "\n",
    "for i in range(len(top_5)):\n",
    "    guess = heirarchal_clustering.make_prediction(clustered_seqs[i], sample_size=15)\n",
    "    for k, original_strand in enumerate(original_strands):\n",
    "        rec = get_recovery_percentage(guess, original_strand)\n",
    "        print(f\"{k} {rec} recovered by {i}\".format())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs further testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
