{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing recovery using heirarchal clustering on barcoded sequencing data \n",
    "https://github.com/ImperialCollegeLondon/sequencingData/tree/main/200125%20-%20Full-Circle%20C000121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import random\n",
    "import heirarchal_clustering\n",
    "import kmeans_clustering\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from clustering import kmerDNA\n",
    "from Levenshtein import ratio\n",
    "from sklearn.preprocessing import normalize\n",
    "import aligned_clustering\n",
    "import cluster_merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the fastq files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_fastq_filepath = r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\sequencingData\\200125 - Full-Circle C000121\\Sample1\\Sample1.fastq\\Sample1.fastq\"\n",
    "\n",
    "sequenced_strands = utils.get_fastq_records(fastq_filepath=example_fastq_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_filepaths_common_string = r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\sequencingData\\200125 - Full-Circle C000121\\Sample{a}\\Sample{a}.fastq\\Sample{a}.fastq\"\n",
    "fastq_filepaths = [fastq_filepaths_common_string.format(a=i) for i in range(1, 7)]\n",
    "fastq_filepaths = [fastq_filepaths[0], fastq_filepaths[2], fastq_filepaths[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenced_strands_arr = [utils.get_fastq_records(fastq_filepath=i) for i in fastq_filepaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenced_strands_arr[2] = random.sample(sequenced_strands_arr[2], 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loading original strands from the readme\n",
    "# Selecting only the 1st, 3rd and 5th sample\n",
    "\n",
    "original_strands = [\n",
    "    \"AGTGTCTGTGACCAGTACGACCCAGTACCGTCACGGTTAGGAAGCTCCTCGCTTCTTAGCCGTCACGCCAAAGTG\",\n",
    "    \"TCGAAAGTGGAGCCGCGGCGACACTCATCTGCTATACAGTAGCTATACGACGATATGACGTGAGCGCTGACGGACCGGCGCTCAACTGGC\",\n",
    "    \"AGTGCAACAAGTCAATCCGTTTCCCCAAGGAGGCCTCCTGGAACAATGAATTATGGCGCCAAGACATGGGGGATCCTAACTGGGGCGCCGACCTGGAGAAACGATCCGGAGGTGCCAGGATCGTCTCTGGAACGCTCCGAAAGTCTTGTT\"\n",
    "]\n",
    "\n",
    "strand_pool = [x for j in sequenced_strands_arr for x in j]\n",
    "#random.shuffle(strand_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levenshtien distance just may not be fast enough to scale to all of these reads. I might need to figure out how to do automata. Hmm, or do kmeans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47419it [00:42, 1121.20it/s]\n"
     ]
    }
   ],
   "source": [
    "freq_counts = kmeans_clustering.get_kmer_frequency_counts(strand_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normalised_freq_counts = kmeans_clustering.normalise_frequency_counts(freq_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "clusters = kmeans_clustering.cluster(normalised_freq_counts, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate out into clusters\n",
    "# Need some metric to evaluate clustering - maybe with barcodes\n",
    "labels = list(clusters.labels_)\n",
    "\n",
    "clustered_seq_ids = [[strand_pool[ind].description.split()[8] for ind, cluster in enumerate(labels) if cluster==j] for j in range(n_clusters)]\n",
    "clustered_seqs = [[strand_pool[ind] for ind, cluster in enumerate(labels) if cluster==j] for j in range(n_clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Counter({'barcode=barcode27': 18064,\n",
       "          'barcode=barcode25': 10409,\n",
       "          'barcode=barcode30': 845}),\n",
       " Counter({'barcode=barcode30': 14061,\n",
       "          'barcode=barcode25': 15,\n",
       "          'barcode=barcode27': 2}),\n",
       " Counter({'barcode=barcode25': 3627,\n",
       "          'barcode=barcode27': 302,\n",
       "          'barcode=barcode30': 94})]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[Counter(i) for i in clustered_seqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45933014354066987"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.align(str(clustered_seqs[1][6].seq), original_strands[2], identity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "\n",
      "0.9933774834437086\n",
      "0.9933333333333333\n",
      "\n",
      "0.4897959183673469\n",
      "0.22\n",
      "\n",
      "0.4948453608247423\n",
      "0.22666666666666666\n",
      "\n",
      "0.5204081632653061\n",
      "0.44666666666666666\n",
      "\n",
      "0.6304347826086957\n",
      "0.54\n",
      "\n",
      "0.4948453608247423\n",
      "0.22666666666666666\n",
      "\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "0.9867549668874173\n",
      "0.8066666666666666\n",
      "\n",
      "1.0\n",
      "1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from each cluster sample randomly 15 and then make 3 guesses\n",
    "\n",
    "for i in range(10):\n",
    "    sampled_seqs = random.sample(clustered_seqs[1], 5)\n",
    "    muscled = aligned_clustering.multiple_alignment_muscle([str(i.seq) for i in sampled_seqs])\n",
    "    consensus_strand = cluster_merging.majority_merge(muscled)\n",
    "    print(utils.align(consensus_strand, original_strands[2], identity=True))\n",
    "    print(utils.get_recovery_percentage(consensus_strand, original_strands[2]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/10000 [00:02<3:54:49,  1.41s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[274], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mheirarchal_clustering\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_junk_reads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclustered_seqs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Its that O(n2) that is going to kill me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\v2\\heirarchal_clustering.py:23\u001b[0m, in \u001b[0;36mfilter_junk_reads\u001b[1;34m(records, ids, similarity_threshold)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Checking if the record is already in the filtered pool\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m record_\u001b[38;5;241m.\u001b[39mseq \u001b[38;5;129;01min\u001b[39;00m filtered_seqs:\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m similarity_threshold:\n\u001b[0;32m     24\u001b[0m         filtered_records\u001b[38;5;241m.\u001b[39mappend(record_)\n\u001b[0;32m     25\u001b[0m         filtered_seqs\u001b[38;5;241m.\u001b[39madd(record_\u001b[38;5;241m.\u001b[39mseq)\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\Levenshtein\\__init__.py:179\u001b[0m, in \u001b[0;36mratio\u001b[1;34m(s1, s2, processor, score_cutoff)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mratio\u001b[39m(s1, s2, \u001b[38;5;241m*\u001b[39m, processor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, score_cutoff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    134\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m    Calculates a normalized indel similarity in the range [0, 1].\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    The indel distance calculates the minimum number of insertions and deletions\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m    0.8571428571428572\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_Indel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_cutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscore_cutoff\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32msrc/rapidfuzz/distance/metrics_cpp.pyx:605\u001b[0m, in \u001b[0;36mrapidfuzz.distance.metrics_cpp_avx2.indel_normalized_similarity\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m./src/rapidfuzz/cpp_common.pxd:421\u001b[0m, in \u001b[0;36mcpp_common.preprocess_strings\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m./src/rapidfuzz/cpp_common.pxd:363\u001b[0m, in \u001b[0;36mcpp_common.conv_sequence\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m./src/rapidfuzz/cpp_common.pxd:315\u001b[0m, in \u001b[0;36mcpp_common.hash_sequence\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\site-packages\\Bio\\Seq.py:522\u001b[0m, in \u001b[0;36m_SeqAbstractBaseClass.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m    505\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a subsequence as a single letter or as a sequence object.\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03m    If the index is an integer, a single letter is returned as a Python\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;124;03m    MutableSeq('ACG')\u001b[39;00m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumbers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIntegral\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    523\u001b[0m         \u001b[38;5;66;03m# Return a single letter as a string\u001b[39;00m\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mchr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[index])\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;66;03m# Return the (sub)sequence as another Seq/MutableSeq object\u001b[39;00m\n",
      "File \u001b[1;32m<frozen abc>:117\u001b[0m, in \u001b[0;36m__instancecheck__\u001b[1;34m(cls, instance)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "heirarchal_clustering.filter_junk_reads(clustered_seqs[0][:10000])\n",
    "\n",
    "# Its that O(n2) that is going to kill me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
