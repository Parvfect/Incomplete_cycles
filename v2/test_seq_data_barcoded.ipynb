{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing recovery using heirarchal clustering on barcoded sequencing data \n",
    "https://github.com/ImperialCollegeLondon/sequencingData/tree/main/200125%20-%20Full-Circle%20C000121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import random\n",
    "import heirarchal_clustering\n",
    "import kmeans_clustering\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from clustering import kmerDNA\n",
    "from Levenshtein import ratio\n",
    "from sklearn.preprocessing import normalize\n",
    "import aligned_clustering\n",
    "import cluster_merging\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edit_distance_matrix(strands):\n",
    "    \"\"\"\n",
    "    Returns the edit distance matrix for the strands\n",
    "    O(n^2)\n",
    "    \"\"\"\n",
    "    n_strands = len(strands)\n",
    "    edit_distance_matrix = np.zeros([n_strands, n_strands])\n",
    "    for i in range(n_strands - 1):\n",
    "        for j in range(i + 1, n_strands):\n",
    "            edit_distance_matrix[i,j] = edit_distance_matrix[j, i] = ratio(strands[i], strands[j])\n",
    "\n",
    "    return edit_distance_matrix\n",
    "\n",
    "def calculate_centroid(strands: list[str]):\n",
    "    edit_distance_matrix = get_edit_distance_matrix(strands)\n",
    "\n",
    "    distances = [sum(edit_distance_matrix[i, :]) for i in range(len(edit_distance_matrix))]\n",
    "    return strands[distances.index(min(distances))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the fastq files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_fastq_filepath = r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\sequencingData\\200125 - Full-Circle C000121\\Sample1\\Sample1.fastq\\Sample1.fastq\"\n",
    "\n",
    "sequenced_strands = utils.get_fastq_records(fastq_filepath=example_fastq_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_filepaths_common_string = r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\sequencingData\\200125 - Full-Circle C000121\\Sample{a}\\Sample{a}.fastq\\Sample{a}.fastq\"\n",
    "fastq_filepaths = [fastq_filepaths_common_string.format(a=i) for i in range(1, 7)]\n",
    "fastq_filepaths = [fastq_filepaths[0], fastq_filepaths[2], fastq_filepaths[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenced_strands_arr = [utils.get_fastq_records(fastq_filepath=i) for i in fastq_filepaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loading original strands from the readme\n",
    "# Selecting only the 1st, 3rd and 5th sample\n",
    "\n",
    "original_strands = [\n",
    "    \"AGTGTCTGTGACCAGTACGACCCAGTACCGTCACGGTTAGGAAGCTCCTCGCTTCTTAGCCGTCACGCCAAAGTG\",\n",
    "    \"TCGAAAGTGGAGCCGCGGCGACACTCATCTGCTATACAGTAGCTATACGACGATATGACGTGAGCGCTGACGGACCGGCGCTCAACTGGC\",\n",
    "    \"AGTGCAACAAGTCAATCCGTTTCCCCAAGGAGGCCTCCTGGAACAATGAATTATGGCGCCAAGACATGGGGGATCCTAACTGGGGCGCCGACCTGGAGAAACGATCCGGAGGTGCCAGGATCGTCTCTGGAACGCTCCGAAAGTCTTGTT\"\n",
    "]\n",
    "\n",
    "# Length filtering\n",
    "sequenced_strands_arr = [[i for i in j if len(i) > len(original_strands[k]) - 10 and len(i) < len(original_strands[k]) + 10] for k, j in enumerate(sequenced_strands_arr)]\n",
    "\n",
    "strand_pool = [x for j in sequenced_strands_arr for x in j]\n",
    "random.shuffle(strand_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenced_strands = [str(i.seq) for i in sequenced_strands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total strands 14051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14051it [00:02, 6181.39it/s]\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import re\n",
    "\n",
    "clusters, centroids = heirarchal_clustering.cluster_trivial(sequenced_strands, similarity_threshold=0.95, use_centroids=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levenshtien distance just may not be fast enough to scale to all of these reads. I might need to figure out how to do automata. Hmm, or do kmeans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clustered_seqs = [[str(strand_pool[ind].seq) for ind in j] for j in clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6622516556291391 recovered by 0\n",
      "0.6164383561643836\n",
      "3222 elements in the cluster\n",
      "126.26070763500931 mean length of strand in cluster\n",
      "31.161983463888493 mean std of strand in cluster\n",
      "\n",
      "1 0.6403940886699507 recovered by 1\n",
      "0.6134969325153374\n",
      "111 elements in the cluster\n",
      "126.21621621621621 mean length of strand in cluster\n",
      "31.657060298834786 mean std of strand in cluster\n",
      "\n",
      "0 0.9866666666666667 recovered by 3\n",
      "0.6620689655172414\n",
      "3347 elements in the cluster\n",
      "126.90319689273977 mean length of strand in cluster\n",
      "30.912990433313 mean std of strand in cluster\n",
      "\n",
      "0 0.7246376811594203 recovered by 4\n",
      "0.9536423841059603\n",
      "32 elements in the cluster\n",
      "127.9375 mean length of strand in cluster\n",
      "30.168213300591734 mean std of strand in cluster\n",
      "\n",
      "0 0.7978723404255319 recovered by 5\n",
      "0.9801324503311258\n",
      "123 elements in the cluster\n",
      "123.32520325203252 mean length of strand in cluster\n",
      "31.604130617898036 mean std of strand in cluster\n",
      "\n",
      "0 0.7226890756302521 recovered by 6\n",
      "0.6622516556291391\n",
      "119 elements in the cluster\n",
      "125.61344537815125 mean length of strand in cluster\n",
      "30.997725382448177 mean std of strand in cluster\n",
      "\n",
      "0 0.644808743169399 recovered by 7\n",
      "0.6622516556291391\n",
      "123 elements in the cluster\n",
      "127.17886178861788 mean length of strand in cluster\n",
      "30.806511960822174 mean std of strand in cluster\n",
      "\n",
      "0 0.6696428571428572 recovered by 8\n",
      "0.6027397260273972\n",
      "1429 elements in the cluster\n",
      "126.15675297410776 mean length of strand in cluster\n",
      "31.095339604032834 mean std of strand in cluster\n",
      "\n",
      "0 0.7692307692307692 recovered by 10\n",
      "0.6533333333333333\n",
      "152 elements in the cluster\n",
      "130.09868421052633 mean length of strand in cluster\n",
      "29.183575019182914 mean std of strand in cluster\n",
      "\n",
      "2 0.6287625418060201 recovered by 14\n",
      "0.5181818181818182\n",
      "1808 elements in the cluster\n",
      "126.74944690265487 mean length of strand in cluster\n",
      "30.914486496751003 mean std of strand in cluster\n",
      "\n",
      "2 0.6357615894039735 recovered by 16\n",
      "0.5429864253393666\n",
      "35 elements in the cluster\n",
      "125.77142857142857 mean length of strand in cluster\n",
      "32.04022981394816 mean std of strand in cluster\n",
      "\n",
      "0 0.6268656716417911 recovered by 17\n",
      "0.6433566433566433\n",
      "90 elements in the cluster\n",
      "124.55555555555556 mean length of strand in cluster\n",
      "31.275162708915452 mean std of strand in cluster\n",
      "\n",
      "2 0.5927835051546392 recovered by 18\n",
      "0.5560538116591929\n",
      "127 elements in the cluster\n",
      "130.6771653543307 mean length of strand in cluster\n",
      "29.459135419786495 mean std of strand in cluster\n",
      "\n",
      "0 0.6726457399103138 recovered by 27\n",
      "0.624113475177305\n",
      "170 elements in the cluster\n",
      "124.4235294117647 mean length of strand in cluster\n",
      "31.36197640477782 mean std of strand in cluster\n",
      "\n",
      "0 0.6944444444444444 recovered by 29\n",
      "0.9933774834437086\n",
      "46 elements in the cluster\n",
      "130.15217391304347 mean length of strand in cluster\n",
      "30.485183422731442 mean std of strand in cluster\n",
      "\n",
      "0 0.6849315068493151 recovered by 36\n",
      "0.9379310344827586\n",
      "50 elements in the cluster\n",
      "122.46 mean length of strand in cluster\n",
      "31.628600980757906 mean std of strand in cluster\n",
      "\n",
      "0 0.7936507936507937 recovered by 37\n",
      "0.96\n",
      "207 elements in the cluster\n",
      "127.01449275362319 mean length of strand in cluster\n",
      "30.852693218728593 mean std of strand in cluster\n",
      "\n",
      "0 0.6944444444444444 recovered by 39\n",
      "0.6711409395973154\n",
      "32 elements in the cluster\n",
      "116.96875 mean length of strand in cluster\n",
      "31.078011092048666 mean std of strand in cluster\n",
      "\n",
      "0 0.6550218340611353 recovered by 50\n",
      "0.6490066225165563\n",
      "150 elements in the cluster\n",
      "125.49333333333334 mean length of strand in cluster\n",
      "31.03089786361687 mean std of strand in cluster\n",
      "\n",
      "2 0.6290322580645161 recovered by 58\n",
      "0.5575221238938053\n",
      "39 elements in the cluster\n",
      "137.84615384615384 mean length of strand in cluster\n",
      "25.61003255090439 mean std of strand in cluster\n",
      "\n",
      "0 0.6218487394957983 recovered by 69\n",
      "0.6666666666666667\n",
      "105 elements in the cluster\n",
      "124.91428571428571 mean length of strand in cluster\n",
      "31.444619279499204 mean std of strand in cluster\n",
      "\n",
      "0 0.6756756756756757 recovered by 80\n",
      "0.9866666666666667\n",
      "49 elements in the cluster\n",
      "129.16326530612244 mean length of strand in cluster\n",
      "29.957348550813354 mean std of strand in cluster\n",
      "\n",
      "0 0.7177033492822966 recovered by 162\n",
      "0.9668874172185431\n",
      "39 elements in the cluster\n",
      "116.56410256410257 mean length of strand in cluster\n",
      "31.853667720869 mean std of strand in cluster\n",
      "\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "\n",
    "original_strand_guessed_best = []\n",
    "counter = 0\n",
    "\n",
    "for ind, i in enumerate(centroids):\n",
    "    \n",
    "    best_guessed = 0\n",
    "    best_rec = 0.0\n",
    "    for k, original_strand in enumerate(original_strands):\n",
    "        rec = ratio(i, original_strand)\n",
    "\n",
    "        if rec > best_rec:\n",
    "            best_guessed = k\n",
    "            best_rec = rec\n",
    "\n",
    "    original_strand_guessed_best.append(best_guessed)\n",
    "    if len(clusters[ind]) > 30:\n",
    "        print(f\"{best_guessed} {best_rec} recovered by {ind}\".format())\n",
    "\n",
    "        centroid = calculate_centroid(clustered_seqs[ind])\n",
    "        print(ratio(original_strands[best_guessed], centroid))\n",
    "        #print(len(i))\n",
    "        print(f\"{len(clusters[ind])} elements in the cluster\")\n",
    "        print(f\"{np.mean([len(i) for i in clustered_seqs[ind]])} mean length of strand in cluster\")\n",
    "        print(f\"{np.std([len(i) for i in clustered_seqs[ind]])} mean std of strand in cluster\")\n",
    "        counter += 1\n",
    "        print()\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 is a guess for 0 with 0.21333333333333335\n",
      "0 is a guess for 1 with 1.0\n",
      "0 is a guess for 2 with 0.12\n",
      "1 is a guess for 0 with 0.28\n",
      "1 is a guess for 1 with 0.35555555555555557\n",
      "1 is a guess for 2 with 0.12666666666666668\n",
      "2 is a guess for 0 with 0.26666666666666666\n",
      "2 is a guess for 1 with 0.18888888888888888\n",
      "2 is a guess for 2 with 1.0\n",
      "3 is a guess for 0 with 0.32\n",
      "3 is a guess for 1 with 0.24444444444444444\n",
      "3 is a guess for 2 with 0.22666666666666666\n",
      "4 is a guess for 0 with 1.0\n",
      "4 is a guess for 1 with 0.17777777777777778\n",
      "4 is a guess for 2 with 0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "for k, guess in enumerate(guesses):\n",
    "    for i, original_strand in enumerate(original_strands):\n",
    "        rec = utils.get_recovery_percentage(guess, original_strand)\n",
    "        print(\"{} is a guess for {} with {}\".format(k, i, rec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "guess_clusters = heirarchal_clustering.cluster_trivial(guesses, similarity_threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TCGAAAGTGGAGCCGCGGCGACACTCATCTGCTATACAGTAGCTATACGACGATATGACGTGAGCGCTGACGGACCGGCGCTCAACTGGCA': [0],\n",
       " 'GCCAGTTGAGCGCCGGTCCGTCAGCGCTCACGTCATATCGTCGTATAGCTACTGTATAGCAGATGAGTGTCGCCGCGGCTCCACTTTCGAA': [1],\n",
       " 'AGTGCAACAAGTCAATCCGTTTCCCCAAGGAGGCCTCCTGGAACAATGAATTATGGCGCCAAGACATGGGGGATCCTAACTGGGGCGCCGACCTGGAGAAACGATCCGGAGGTGCCAGGATCGTCTCTGGAACGCTCCGAAAGTCTTGTTA': [2],\n",
       " 'AACAAGACTTTCGGAGCGTTCCAGAGACGATCCTGGCACCTCCGGATCGTTTCTCCAGGTCGGCGCCCCAGTTAGGATCCCCCATGTCTTGGCGCCATAATTCATTGTTCCAGGAGGCCTCCTTGGGGAAACGGATTGACTTGTTGCACTA': [3],\n",
       " 'AGTGTCTGTGACCAGTACGACCCAGTACCGTCACGGTTAGGAAGCTCCTCGCTTCTTAGCCGTCACGCCAAAGTGA': [4]}"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
