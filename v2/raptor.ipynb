{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import heirarchal_clustering\n",
    "from Levenshtein import ratio, distance\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the original strands\n",
    "original_strands, ids = utils.read_synthesized_strands_from_file(file_path=r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\v2\\raptor_data\\cat.jpg_RU10 2.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1954567it [02:06, 15461.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loading the original strands\n",
    "reads = utils.postprocess_badread_sequencing_data(fastq_filepath=r\"C:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\v2\\raptor_data\\reads.fastq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled = random.sample(reads, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 8244.53it/s]\n"
     ]
    }
   ],
   "source": [
    "sample_stats = utils.get_sample_statistics(records=sampled, original_strands=original_strands, original_strand_ids=ids, distance_threshold=40, reference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'distance_threshold': 40,\n",
       " 'strands_by_index': array([ 8., 14.,  8., ..., 12.,  8.,  9.]),\n",
       " 'mean_strands_per_index': 9.27788844621514,\n",
       " 'std_strands_per_index': 2.9829310439656096,\n",
       " 'unique_matches': 1003,\n",
       " 'n_straight': 4547,\n",
       " 'n_reverse': 4768,\n",
       " 'unmatched': 471}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_sampled = [str(i.seq) for i in sampled]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total strands 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [11:27<00:00, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters = 2181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_inds, cluster_strands, centroids = heirarchal_clustering.cluster_trivial(seqs_sampled, use_centroids=False, distance_threshold=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = utils.get_sort_by_sublists_length(cluster_inds)\n",
    "\n",
    "sorted_clusters = [cluster_inds[i] for i in indices]\n",
    "sorted_centroids = [centroids[i] for i in indices]\n",
    "sorted_clustered_seqs = [cluster_strands[i] for i in indices]\n",
    "\n",
    "centroids = sorted_centroids\n",
    "clusters = sorted_clusters\n",
    "clustered_seqs = sorted_clustered_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_best_candidates_and_recoveries(original_strands, candidates):\n",
    "    \"\"\"\n",
    "    For a given set of strands, finds the best candidates and returns a dictionary with\n",
    "    the recoveries, the number of fully recovered strands, the best set of candidates and the\n",
    "    original strands\n",
    "    \"\"\"\n",
    "    \n",
    "    fully_recovered_strands = 0\n",
    "    recoveries = []\n",
    "    partially_recovered_recoveries = []\n",
    "    best_candidates = []\n",
    "\n",
    "    for strand in tqdm(original_strands):\n",
    "        if strand in candidates:\n",
    "            fully_recovered_strands += 1\n",
    "            recoveries.append(1.0)\n",
    "            best_candidates.append(strand)\n",
    "        else:\n",
    "            best_recovery_within_candidates = 0.0\n",
    "            best_candidate = \"\"\n",
    "            for candidate in candidates:\n",
    "                rev_candidate = utils.reverse_complement(candidate)\n",
    "                strand_recovery = ratio(candidate, strand)\n",
    "\n",
    "                if strand_recovery > best_recovery_within_candidates:\n",
    "                    best_recovery_within_candidates = strand_recovery\n",
    "                    best_candidate = candidate\n",
    "\n",
    "                strand_recovery = ratio(rev_candidate, strand)\n",
    "\n",
    "                if strand_recovery > best_recovery_within_candidates:\n",
    "                    best_recovery_within_candidates = strand_recovery\n",
    "                    best_candidate = candidate\n",
    "\n",
    "            recoveries.append(best_recovery_within_candidates)\n",
    "            partially_recovered_recoveries.append(best_recovery_within_candidates)\n",
    "            best_candidates.append(best_candidate)\n",
    "\n",
    "    return {\n",
    "        \"recoveries\": recoveries,\n",
    "        \"fully_recovered_strands\": fully_recovered_strands,\n",
    "        \"partially_recovered_recoveries\": partially_recovered_recoveries,\n",
    "        \"best_candidates\": best_candidates,\n",
    "        \"original_strands\": original_strands\n",
    "    }\n",
    "\n",
    "\n",
    "def check_clusters(original_strands, cluster_inds):\n",
    "\n",
    "    for i in cluster_inds:\n",
    "        record = reads[i[0]]\n",
    "        try:\n",
    "            print(ratio(record, original_strands[ids.index(utils.get_badread_strand_id(record))]))\n",
    "            print(len(i))\n",
    "            print()\n",
    "        except:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.888769849476563)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(recoveries['recoveries'][:1004])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1004"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(original_strands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [00:00<00:00, 24248.58it/s]\n"
     ]
    }
   ],
   "source": [
    "centroid_indices = [i[0] for i in cluster_inds]\n",
    "centroid_records = [sampled[j] for j in centroid_indices][:1004]\n",
    "\n",
    "centroid_stats = utils.get_sample_statistics(records = centroid_records, original_strands=original_strands, original_strand_ids=ids, reference=True, distance_threshold=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'distance_threshold': 40,\n",
       " 'strands_by_index': array([1., 1., 1., ..., 1., 1., 1.]),\n",
       " 'mean_strands_per_index': 0.9800796812749004,\n",
       " 'std_strands_per_index': 0.3860123979098825,\n",
       " 'unique_matches': 919,\n",
       " 'n_straight': 444,\n",
       " 'n_reverse': 540,\n",
       " 'unmatched': 20}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc4f3627a2d4b64995146d5b3e665a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m guesses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m)):\n\u001b[1;32m----> 3\u001b[0m     guesses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mheirarchal_clustering\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclustered_seqs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Parv\\Doc\\RA\\Projects\\incomplete_cycles\\v2\\heirarchal_clustering.py:123\u001b[0m, in \u001b[0;36mmake_prediction\u001b[1;34m(cluster, sample_size)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_prediction\u001b[39m(cluster, sample_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m--> 123\u001b[0m     cluster \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m majority_merge(multiple_alignment_muscle(cluster))\n",
      "File \u001b[1;32mc:\\Users\\Parv\\anaconda3\\envs\\pytorch_gpu\\Lib\\random.py:430\u001b[0m, in \u001b[0;36mRandom.sample\u001b[1;34m(self, population, k, counts)\u001b[0m\n\u001b[0;32m    428\u001b[0m randbelow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n\u001b[1;32m--> 430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample larger than population or is negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    431\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m k\n\u001b[0;32m    432\u001b[0m setsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m21\u001b[39m        \u001b[38;5;66;03m# size of a small set minus size of an empty list\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "guesses = []\n",
    "for i in tqdm(range(1000)):\n",
    "    guesses.append(heirarchal_clustering.make_prediction(clustered_seqs[i], 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833 found by 0\n",
      "392 found by r1\n",
      "197 found by r2\n",
      "147 found by r4\n",
      "372 found by r7\n",
      "933 found by 8\n",
      "945 found by r9\n",
      "896 found by 10\n",
      "876 found by r11\n",
      "322 found by 12\n",
      "468 found by 13\n",
      "705 found by r14\n",
      "777 found by 15\n",
      "492 found by 16\n",
      "669 found by r17\n",
      "901 found by 18\n",
      "388 found by r19\n",
      "217 found by 20\n",
      "476 found by 36\n",
      "446 found by 45\n",
      "304 found by 46\n",
      "544 found by 47\n",
      "46 found by 48\n",
      "187 found by r49\n",
      "971 found by 50\n",
      "639 found by r51\n",
      "814 found by 52\n",
      "161 found by r53\n",
      "265 found by r54\n",
      "843 found by r55\n",
      "327 found by r56\n",
      "564 found by 57\n",
      "838 found by r58\n",
      "683 found by 59\n",
      "520 found by r60\n",
      "359 found by r61\n",
      "723 found by 62\n",
      "882 found by r63\n",
      "425 found by 155\n",
      "754 found by r156\n",
      "34 found by r157\n",
      "956 found by 158\n",
      "365 found by r159\n",
      "608 found by r160\n",
      "986 found by r161\n",
      "212 found by r162\n",
      "10 found by r163\n",
      "94 found by 164\n",
      "988 found by r165\n",
      "373 found by 371\n",
      "306 found by r618\n",
      "936 found by 619\n",
      "310 found by r620\n",
      "214 found by r621\n",
      "743 found by 622\n",
      "70 found by r623\n",
      "637 found by r624\n",
      "847 found by r625\n",
      "281 found by 626\n",
      "676 found by 627\n",
      "722 found by r628\n",
      "116 found by 629\n",
      "713 found by 630\n",
      "726 found by r631\n",
      "784 found by 632\n",
      "801 found by r633\n",
      "550 found by r634\n",
      "675 found by r635\n",
      "717 found by r653\n",
      "622 found by 796\n",
      "855 found by r797\n",
      "769 found by r798\n",
      "391 found by r799\n",
      "318 found by r800\n",
      "390 found by 801\n"
     ]
    }
   ],
   "source": [
    "\n",
    "distance_threshold = 40\n",
    "\n",
    "strands_by_index = np.zeros(len(original_strands))\n",
    "straight_strands = 0\n",
    "reverse_strands = 0\n",
    "\n",
    "for ind, i in enumerate(guesses):\n",
    "\n",
    "    revseq = utils.reverse_complement(i)\n",
    "\n",
    "    record = sampled[cluster_inds[ind][0]]\n",
    "\n",
    "    strand_id = utils.get_badread_strand_id(record)\n",
    "    #synthesized_id = strand_ids_synthesized[strand_id]\n",
    "    #index = original_strand_ids.index(synthesized_id)\n",
    "    index = ids.index(strand_id)\n",
    "    strand = original_strands[index]\n",
    "\n",
    "    if distance(i, strand) <= distance_threshold:\n",
    "        strands_by_index[index] += 1\n",
    "        straight_strands += 1\n",
    "        found_flag = True\n",
    "        print(f\"{index} found by {ind}\")\n",
    "\n",
    "    elif distance(revseq, strand) <= distance_threshold:\n",
    "        strands_by_index[index] += 1\n",
    "        reverse_strands += 1\n",
    "        found_flag = True\n",
    "        print(f\"{index} found by r{ind}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(75.0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(strands_by_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_strands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
